---
title: "US President Prediction"
subtitle: "Predict the results of 2024 US President Election"
author: 
  - Yun Chu
  - Felix Li
  - Wen Han Zhao 
thanks: "Code and data are available at: [https://github.com/younazhao/US-President-Prediction/tree/main](https://github.com/younazhao/US-President-Prediction/tree/main)."
date: 22 October 2024
date-format: long
abstract: "In this study, we aim to study the 2024 U.S. Presidential Election with the methodology of  polls of polls across various states. With the insightful analyses on polls provided by Redfiled & Wilton Strategies, the conducted survey on the population highlights various key point for the prediction of US president. Using Generalized Linear Models (GLMs), this report analyzes the accuracy of prediction in president votes through several key variables from pollster. The model incorporates variables such as pollscore, methodology, transparency_score and hypothetical. The prediction finding highlights the significance of candicate trustworthiness among the voter decision, providing insights for swing voters. This analysis offers valuable information into the potential electoral outcomes driving the 2024 US president election. "
format: pdf
number-sections: true
bibliography: references.bib
---

```{r}
#| include: false
#| warning: false
#| message: false
library(tidyverse)
library(knitr)
library(kableExtra)
library(readr)
library(dplyr)
```


# Introduction

Overview paragraph

Estimand paragraph

Results paragraph

Why it matters paragraph

Telegraphing paragraph: The remainder of this paper is structured as follows. @sec-data....






# Data {#sec-data}

## Overview

We use the statistical programming language R [@citeR].... Our data.... Following @tellingstories, we consider...

Overview text

## Measurement
	
Some paragraphs about how we go from a phenomena in the world to an entry in the dataset.

## Outcome variables

Talk way more about it. 

## Predictor variables

Add graphs, tables and text.

Use sub-sub-headings for each outcome variable and feel free to combine a few into one if they go together naturally.



# Model {#set-model}

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix @sec-model-details].

## Model set-up

Define $y_i$ as the percentage of support for a candicate in a poll.

${y_i} = \beta_0 + \beta_1 pollscore + \beta_2 methodology + \beta_3transparency score + \beta_4 hypothetical + \epsilon$ 

pollscore: A numeric value representing the score or reliability of the pollster in question (e.g., -1.1). "The error and bias we can attribute to a pollster. Negative numbers are better. Stands for "Predictive Optimization of Latent skill Level in Surveys, Considering Overall Record, Empirically.

methodology: The method used to conduct the poll (e.g., Online Panel).

transparency_score: A score reflecting the pollsterâ€™s transparency about their methodology (e.g., 9.0). "A grade for how transparent a pollster is, calculated based on how much information it discloses about its polls and weighted by 
by recency. The highest Transparency Score is 10."
 
hypothetical: Indicates whether the poll is about a hypothetical match-up.

We run the model in R [@citeR].


### Model justification

```{r}
#| echo: false
#| eval: true
#| warning: false
#| message: false

# Library setup
#install.packages("glm")
library(glmnet)
library(ggplot2)
```

```{r}
#| echo: false
#| eval: true
#| label: tbl-model1
#| tbl-cap: "model 1"
#| warning: false
# Get the analysis data
analysis_data <- read_csv(here::here("data/02-analysis_data/analysis_data.csv"))

# Model
glm_model1 <- glm(pct ~ pollscore + methodology + transparency_score + hypothetical, data = analysis_data, family = gaussian()) 

# Get the summary
model_summary <- summary(glm_model1)

# Convert the summary coefficients to a data frame
summary_table <- as.data.frame(model_summary$coefficients)

# Create a table with a caption and control the size
kable(summary_table, caption = "Model 1 Summary Table", size = "small")
```

## Lasso Regularization {#sec-model-lassoregularization}
Lasso Regularization is performed to see if the selected variable in our model would best predict the results of polls percentage of a candidate. If the variable do not align with our actual numbers, we should consider other variables or a interaction variable. 

```{r}
#| echo: false
#| eval: true
#| label: tbl-lassoregularization
#| tbl-cap: "lasso regularization"
#| warning: false
# Prepare the predictors
x <- model.matrix(pct ~ pollscore + methodology + transparency_score + hypothetical, data = analysis_data)[, -1]

# Prepare the response variable
y <- analysis_data$pct

# Lasso regression (alpha = 1)
lasso_model <- glmnet(x, y, alpha = 1, family = "gaussian")

# Cross-validation for Lasso
cv_lasso <- cv.glmnet(x, y, alpha = 1, family = "gaussian")

plot(cv_lasso)

# Get the best lambda
best_lambda_lasso <- cv_lasso$lambda.min

# Refit Lasso with the optimal lambda
lasso_final_model <- glmnet(x, y, alpha = 1, lambda = best_lambda_lasso, family = "gaussian")

# View Lasso coefficients
coef.lasso <- coef(lasso_final_model)

# Predict using Lasso
pred_lasso <- predict(lasso_final_model, s = best_lambda_lasso, newx = x)

```


Computing the Mean Square Error would give us a sense of our lasso model prediction. 
```{r}
#| echo: false
#| eval: true
#| label: tbl-msr
#| tbl-cap: "Mean Squared Error"
#| warning: false
# Calculate Mean Squared Error
mse <- mean((y - pred_lasso)^2)
cat("Mean Squared Error:", mse, "\n")

# Calculate R-squared
sst <- sum((y - mean(y))^2)
sse <- sum((y - pred_lasso)^2)
r_squared <- 1 - (sse / sst)
cat("R-squared:", r_squared, "\n")

# Create a data frame for plotting
results_df <- data.frame(
  Metric = c("SST", "SSE", "R-squared"),
  Value = c(sst, sse, r_squared)
)

kable(results_df, caption = "Mean Squared Error Table")
```


From this graph, we can see that the cluster points do not perfectly align on the line of the best fit so we should still investigate in other variables. 
```{r}
#| echo: false
#| eval: true
#| label: tbl-actualvspredicted
#| tbl-cap: "actual vs predicted"
#| warning: false

# Compare predicted vs actual values
comparison <- data.frame(Actual = y, Predicted = as.vector(pred_lasso))

kable(head(comparison), caption = "Actual vs Predicted")

# Plot actual vs predicted values
ggplot(comparison, aes(x = Actual, y = Predicted)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title = "Actual vs Predicted Values",
       x = "Actual Values",
       y = "Predicted Values") +
  theme_minimal()
```


\newpage

\appendix

# Appendix {-}


# Additional data details

## pollster methodology analysis

This survey was conducted by Redfield & Wilton Strategies to assess the voting intentions of eligible voters in key U.S. swing states ahead of the 2024 Presidential Election. The primary goal of this poll is to provide an accurate and timely snapshot of public opinion in states where electoral outcomes are uncertain and could have a decisive impact on the overall result of the election. Swing states, due to their political volatility and diverse voter bases, are critical in determining the balance of power in the U.S. electoral system. Understanding voter preferences in these states is essential for political analysts, campaigns, and the general public.

### Population of Interest
The population of interest for this survey consists of all eligible voters residing in major U.S. swing states, specifically Arizona, Florida, Georgia, Michigan, North Carolina, and Pennsylvania. These states are known for their fluctuating political alignments and are expected to play a crucial role in the upcoming election.

### Sampling Frame
The population sampled includes eligible voters from Arizona, Florida, Georgia, Michigan, North Carolina, and Pennsylvania. Participants were selected via an online panel.

### Sample
The sample sizes for each state were as follows:

Arizona: 750 respondents

Florida: 1,350 respondents

Georgia: 927 respondents

Michigan: 970 respondents

North Carolina: 880 respondents

Pennsylvania: 1,070 respondents

## Weakness & Strength of the methodology

In terms of strengths, Redfield & Wilton has a great reputation for producing reliable polling data. They have employ a mix of online and telephone survey, which add in various resources of collecting their data. This approach can help reduce bias. In addition, Redfield & Wilton often target swing states, which makes their polls results important to the US president election.

The weakness of their methodology would incorporate a certain potential bias based on their political leaning of their clients or media. This could cause a certain neutrality in their dataset. 

Overall, Redfield & Wilton has been considered as a competent, reputable and reliable pollster with his variaty and methodology on polls. Even though the pollster contained a potential bias, it has been a reliable resource in prediction of US president election. 


# Model details {#sec-model-details}



\newpage

# Appendix 2 - Idealized Methodology and Survey

## Overview

This section introduces an idealized methodology and survey with $100K budget to predict the 2024 US presidential election. The goal is to maximize the accuracy of the prediction under the budget. The subsections that describe the details of the idealized methodology and survey include sampling approach, respondents recruiting method, data validation, poll aggregation and the survey questions.

### Sampling Approach

Cluster sampling is the sampling approach used. Specifically clusters are the swing states as they are the states that would affect the election result, i.e. Arizona, Florida, Gegorgia, Iowa, Michigan, Nevada, North Carolina, Pennsylvania, and Wisconsin. In each swing state/clusters, units are selected based on postal code. Using simple random sampling, 100 distinct postal codes are randomly selected. People whose living address has the postal codes selected are the target respondents. For the postal codes that lie in the non-residential area, the postal codes would be ignored.

### Recruitment Strategy

The strategy to be implemented to recruit respondents is a combination of physical and online recruitment. 

If the building corresponds to the postal code is a condo building, a paper with QR code to the survey is going to be put in the lobby or elevator, or sent to residents through the property management. If the building is a residential house, then a letter with the QR code would be put in the mailbox. 

All respondents are rewarded with a $5 deposit to their bank account or a gift card of their choice. Each IP address is limited to answer the survey once.

### Data Validation

To improve accuracy of the prediction results, the following data validation approaches will be done.

* Postal Code Validation
 - All the postal codes got from respondents are going to be validated to check if it is one of the randomly selected postal codes. If not, the response would not be considered when the prediction is done.
* Just-for-Rewards Prevention
 - To identify the responses that are not seriously answered, the last question of the survey is set test if the respondents are serious and careful when answering the questions.
* Age Validity
 - Responses with age under 18 but answered "Yes" to "Are you registered to Vote" are discarded.


### Poll Aggregation

For each of the swing states, the result would be calculated based on the votes to Trump versus Harris because they are the candidates with the greatest chances of winning. Based on the decisiveness of the respondents and the likelihood of voting from the responses, the individual votes will be weighted when calculating the results for each swing states.

To aggregate the polls for all states, the result of each states is multiplied by its electoral votes. After summing the electoral votes for Trump or Harris, the estimated electoral votes that Trump or Harris get is available. The candidate that has more than 270 electoral votes would be predicted to win the election {@nationalarchives2024electoral}.

### Survey

Google form of the survey is available here:  https://docs.google.com/forms/d/1obaebX3zqw7WJEd1lHrF-DVBXdZt5tbjHofjsWj9zf8/prefill 

1. What is the postal code of where you live?

2. Are you registered to vote?

* Yes
* No

3. Who would you vote for?

* Donald Trump - Republican
* Kamala Harris - Democrat
* Other Candidates
* Not Decided Yet

4. How decisive are you to vote for the option you chose in the last question?

* Very Decisive
* Pretty Decisive
* A Bit Indecisive
* Very Indecisive

5. How likely are you to vote for the election?

* Very Likely
* A Bit Likely
* Not Likely

6. What age group are you in?

* 0 - 18
* 19 - 30
* 31 - 50
* 51 - 70
* 71+

7.

8.

9.

10. How many characters are present in the word "President"?

* 6
* 8
* 10
* None of the Above

### Budget Specification

* Physical and Online Recruitment: $30,000
* Rewards for Respondents: $50,000
* Data Collection & Validation: $10,000
* Other: $10,000

Total: $100,000

### Conclusion

The survey uses cluster sampling to sample the swing states based on postal codes. After data collection and validation, weighting based on the likelihood of voting and decisiveness of the respondents, the total votes for Donald Trump and Kamala Harris are calulated. The candidate with more than 270 votes are predicted to win the election{@nationalarchives2024electoral}.

# References




